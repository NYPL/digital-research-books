name: ETL Pipeline Tests (Pull Request)

on:
  pull_request:
    types: [opened, synchronize]
    paths:
      - "etl-pipeline/api/**"
      - "etl-pipeline/managers/**"
      - "etl-pipeline/mappings/**"
      - "etl-pipeline/model/**"
      - "etl-pipeline/processes/**"
      - "etl-pipeline/services/**"
      - "etl-pipeline/tests/**"
      - "etl-pipeline/utils/**"
      - "etl-pipeline/dev-requirements.txt"
      - "etl-pipeline/requirements.txt"
      - "etl-pipeline/main.py"
      - "etl-pipeline/Makefile"

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      IS_CI: "true"
      AWS_ACCESS: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      DOCKER_BUILDKIT: 1
      COMPOSE_DOCKER_CLI_BUILD: 1

    steps:
      - uses: actions/checkout@v4

      - name: Install build essentials
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc-12 g++-12
          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 60
          sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 60

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"
          cache: "pip"
          cache-dependency-path: |
            etl-pipeline/requirements.txt
            etl-pipeline/dev-requirements.txt

      - name: Install Python dependencies
        working-directory: ./etl-pipeline
        run: |
          python -m pip install --upgrade pip wheel
          pip install -r requirements.txt -r dev-requirements.txt

      - name: Check formatting
        working-directory: ./etl-pipeline
        run: |
          ruff format --check

      - name: Run unit tests
        working-directory: ./etl-pipeline
        run: |
          make unit

      - name: Build Docker images with cache
        working-directory: ./etl-pipeline
        run: |
          docker compose build --progress plain \
            --build-arg BUILDKIT_INLINE_CACHE=1

      - name: Start services
        working-directory: ./etl-pipeline
        run: |
          docker compose up -d

      - name: Wait for containers
        run: |
          echo "Waiting for services..." && sleep 90

      - name: Run functional and integration tests
        env:
          ENVIRONMENT: local
        working-directory: ./etl-pipeline
        run: |
          make functional integration

      - name: Cleanup
        if: always()
        working-directory: ./etl-pipeline
        run: |
          docker compose down
